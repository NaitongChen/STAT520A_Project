% !TEX root = ../main.tex

% Background section

\section{Introduction}

Change point detection solves the class of problems where one would like to identify times when abrupt changes in the underlying data generating process of a time series occurs. In practice, this setting is widely seen in areas such as stock analysis and climate studies \cite{chen1997testing,elsner2004detecting}. In the literature, a wide variety of approaches, both frequentist and Bayesian, have been developed to efficiently solve the change point problems \cite{killick2012optimal,carlin1992hierarchical}. In the Bayesian approaches, the problem is often framed as estimating the posterior distribution of the change point locations. The common advantages of the Bayesian approach to statistical inference apply in the change point setting. Compared to the point estimates of the change point locations, the posterior distribution of the change point locations of a given sequence provides a more flexible and holistic understanding of the time series. For example, having access to the approximate posterior distribution of the change point locations allows us to estimate the probability that a change has occured at some given time.\\\\
One of the earliest Bayesian approaches to the change point problem is developed in \cite{carlin1992hierarchical} through Markov Chain Monte Carlo (MCMC). Particularly, a Gibbs sampler is used to obtain samples for estimating the posterior distribution of the change point locations. It is worth noting that, although only the detection of a single change point is discussed in \cite{carlin1992hierarchical}, there is a natural extension to the multiple change point setting when the number of change points is known. Specifically, instead of sampling a single change point from the distribution of change points conditioned on all other parameters in the model, a set of change points can be sampled from the conditional distribution over all possible configurations of the change point locations. It is then obvious that as the number of changepoints and the length of the time series grow, the number of possible configurations of the change point locations grows exponentially. As a result, the computational complexity of the Gibbs sampler becomes exponentially more expensive.\\\\
The scalability issue described above is present in virtually all change point detection methods. In fact, many of the more recent developments in MCMC-based approaches can be viewed as trying to bypass this computational bottleneck either through clever reformulation of the problem \cite{stephens1994bayesian,lavielle2001application} or the use of Metropolis-Hastings (MH) and potentially well-designed proposal distributions \cite{green1995reversible,antoch2008application}. The approach in \cite{antoch2008application} is one of the easiest and most intuitive attempts at circumventing the computational challenge posed in \cite{carlin1992hierarchical}. Instead of computing the full conditional distribution of the change point locations, a uniform proposal over all possible configurations of change point locations is accepted/rejected based on the MH ratio. However, while the expensive full conditional distribution no longer needs to be evaluated, exploring this potentially enormous space of change point locations using a uniform proposal may not be the most efficient, thus posing a different challenge.\\\\
In this report, we compare the Bayesian change point detection problems proposed in \cite{carlin1992hierarchical} and \cite{antoch2008application}. Using a piecewise constant model, we would like to explore, under different settings, whether there is a trade-off between evaluating the expensive full conditional distribution and searching over a potentially large space using a cheaper sampler that risks low acceptance probabilities. Through a number of experiments, we find that although the approach in \cite{carlin1992hierarchical} is more favourable in all models that are tested, the approach in \cite{antoch2008application} offers very competitive performance. However, we note that only a uniform proposal distribution is used. By designing more informative proposal distribution, as already been explored in \cite{benson2018adaptive}, proposal-based MCMC methods applied to the change point problems would be a very attractive choice when the number of possible change point configurations is too large to be handled by a Gibbs sampler.\\\\
Below, we start by specifying the piecewise constant model and outlining the procedures of the two MCMC methods before presenting the discussing the experimental results.

% ...